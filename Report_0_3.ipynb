{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchange price analysis of cryptocurrencies\n",
    "## Team: Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "`Project overview`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Methods](#methods)\n",
    "3. [Data](#data)\n",
    "4. [Results](#results)\n",
    "5. [Discussion](#discussion)\n",
    "6. [References](#references)\n",
    "7. [Appendix](#appendix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "Today there are 2068 different crytocurrencies according to coinmarketcap.com [2]. About a year ago there were \"only\" 750 according to a research paper \"A Statistical Analysis of Cryptocurrencie\"[3]. The growth of the industry has been substantial and with as many coins as there are today, it is incredible that one of the cryptocurrencies - Bitcoin, has been able to keep its' majority market share of 55.0%. The original goal of Bitcoin was to work as any other currency, but many see cryptocurrencies as commodities, and use cryptocurrencies as investments instead of means to complete transactions.\n",
    "\n",
    "But how viable are cryptocurrencies as an investment? Can you build investment portfolios of several cryptocurrencies? These are rather interesting questions. In this project we are interested if implementing a bayesian workflow will help to investigate the distributions of cryptocurrencies, and whether there are strong trends in the cryptocurrency market.\n",
    "\n",
    "This project has two objectives. One is to analyse the variation of the exchange price to USD of the coins, and if they can be fit with certain distributions in order to predict potential price variation for a new or existing coin. Second is to see if exchange price for certain coins can be predicted based the exchange price of BTC (Bitcoin). Given the vast amount of different cryptocurrencies, we have narrowed down the data set to only few, thus our inferences might be partial.\n",
    "\n",
    "We first explain what is the data we are working with, followed by methodologies and model types we were using in our Bayesian data analysis. In the end we present our results and conclusions we made based on those results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"data\"></a>\n",
    "We took the coin data compiled by Coin Metrics[1] from coinmarketcap.com. The complete data set has 21400 data points and is a daily time series of market capitalization, price, exchange volume, fees and etc. The time range of the timeseries depends on the cryptocurrency, but some go as far back as 2014 and they all end on November 29 2018. For analysis we narrowed the coins down to have the features we were interested in.\n",
    "\n",
    "#### Features\n",
    "* Market cap (USD)\n",
    "* Price (USD)\n",
    "* Fees\n",
    "* Transaction volume\n",
    "\n",
    "Every feature here is positive real (continuous) value with the exception of fees, as they can also be equal to zero. Further selection (narrowing down) was based on market capitalisation. As a result the following coins ended up in the final set. For the price prediction we picked the coins with big market capitalisation and so that there would be more data points than in the original big coins set.\n",
    "\n",
    "#### Price variation:\n",
    "##### Small coins (marketcap < 160 million on 29th November 2018):\n",
    "* DigiByte (DGB)\n",
    "* Gas (GAS)\n",
    "* PIVX (PIVX)\n",
    "* Vertcoin (VTC)\n",
    "* Waves (WAVES)\n",
    "* Verge (XVG)\n",
    "\n",
    "##### Big coins (marketcap > 1000 million on 29th November 2018):\n",
    "* Bitcoin (BTC)\n",
    "* Ethereum (ETH)\n",
    "* Litecoin (LTC)\n",
    "* Cardano (ADA)\n",
    "* Bitcoin Cash (BCH)\n",
    "\n",
    "#### Price prediction (hand picked):\n",
    "* Bitcoin (BTC)\n",
    "* Ethereum (ETH)\n",
    "* Litecoin (LTC)\n",
    "* Dash (DASH)\n",
    "* Ethereum Classic (ETC)\n",
    "\n",
    "#### Time period\n",
    "For the hand picked currencies limiting the time frame of the data to between the 24th July 2016 and 26th November 2018, gives us a full data set, which means that there isn't any missing data, which should make the preprocessing of the data easier.\n",
    "\n",
    "However, for the other coins the time period was taken based on shortest time-period, without any missing values, of the available coins small and big respectively. As a result for small coins the time period was based on Gas coin with 512 consequtive days, and big coins were based on Cardano with consequtive 425 days. For both data sets the last day is 29th of November 2018.\n",
    "\n",
    "### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crypto currencies by marketcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Symbol', 'Name', 'Market Cap (US $)', 'Price (US $)',\n",
      "       'Circulating Supply', 'Volume (24h)', ' 1h (%)', ' 24h (%)', ' 7d (%)'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/snapshot/november-25.csv')\n",
    "df = df.drop(columns='#')\n",
    "\n",
    "# Remove all coins with no market cap information\n",
    "df = df.dropna()\n",
    "df = df.mask(df.eq('None')).dropna()\n",
    "print(df.columns)\n",
    "\n",
    "df['Market Cap (US $)'] = pd.to_numeric(df['Market Cap (US $)'])\n",
    "\n",
    "names = df['Symbol']\n",
    "m_caps = df['Market Cap (US $)'].values\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(14,5))\n",
    "ax1.bar(names[0:20], m_caps[0:20])\n",
    "ax1.set_xticklabels(names[0:20], rotation=45);\n",
    "explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "names_top8 = [name if i < 8 else '' for i, name in enumerate(names)]\n",
    "\n",
    "ax2.pie(m_caps, labels=names_top8, autopct=None, startangle=90)\n",
    "ax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods <a name=\"methods\"></a>\n",
    "Originally we had also an objective to analyse dependence of transaction volume of each coin on its' transaction fees. However given the time and problems we encountered during the price analysis we decided to narrow our objectives.\n",
    "\n",
    "We decided to split the work into two objectives, one is analysis of price variation and second is price prediction. For price variation we were interested if coins had similarity in the variation distribution as well as value range over which they were varying. For the price prediction we were interested if we could predict price of other coins given the price of the Bitcoin.\n",
    "\n",
    "### Price variation\n",
    "\n",
    "For price variation we excluded the time parameter and looked at how exchange price varies overall and if we can fit a distribution to that variation in order to potentially predict the variance of existing or new currencies.\n",
    "\n",
    "Given several coins, hierarchichal model was chosen as we believed that coins should behave similarly and that they have some common hierarchical prior to the behaviour they are expressing. Hierarchical model was tested using different distributions and as a consequence of the results of preliminary distributions, we ended up transforming the data and applying different set of distributions in our analysis. \n",
    "\n",
    "The workflow followed the demonstration by Michael Betancourt[4]. However, there are some differences in the approach of model analysis as we followed the loo values based on pareto-smoothed importance sampling (further psis-loo) estimation demonstrated on the course, rather than z-s scores. However, it is similar in the summary statistic as we chose histogram plots as our summary statistic of the data and distribution fits.\n",
    "\n",
    "In additon, at first, set of coins with small marketcap was evaluated and final distributions in hierarchical model were applied to big coins (as well as small) to see what were differences and similarities. All the models were run with default Stan parameters, having the Stan code in separate file and using Python to access the Stan framework. Furthermore, our choice for prior distributions were based on the hypothesis that cryptocurrencies should have certain tendencies. Further details are discussed in the Results section.\n",
    "\n",
    "### Price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results <a name=\"results\"></a>\n",
    "\n",
    "The bayesian workflow was done somewhat similarly to the example demonstrated by Michael Betancourt[4]. The difference is that \n",
    "we do not have such great domain expertise and thus did not know how specifically choose our prior and exactly - the parameter values. Which lead to different evaluation of the model. In the workflow example the ranking and z-s scores were used, we on other hand tried out different models and compared the psis-loo values of these models.\n",
    "\n",
    "### Price variation\n",
    "\n",
    "According to the principled bayesian workflow, we were supposed to first build a model based on our prior knowledge and then look and use the data, in order to adapt and modify our model. As a summary statistic for the data and distribution we chose histogram of the data points. In addition the distributions have psis-loo values and optionally effective parameters can be seen in the Appendices A.2. and B.1. We decided to include the stan files of this section in the Appendix A.1. as well as the convergance results (n_eff, R-hat, k-values) in A.2. as there is too much information to present in the main body of the report. We further discuss the results.\n",
    "\n",
    "#### First steps\n",
    "\n",
    "Given that the exchange prices we were dealing with were positive continuous values, the hierarchichal model was thus build on lognormal hierarchical prior, as normal could take real values below 0 and lognormal was restricted to values above 0. We tried to avoid uniform distribution as we believed there are tendencies in cryptocurrency behaviour, which should follow the data type they have. As we were unsure what posterior distribution would the prices follow given the hierarchical prior, we decided to test lognormal as well as chi-square, inverse chi-square and weibull distributions.\n",
    "\n",
    "* lognormal (Stan: y ~ lognormal(mu, sigma))\n",
    "\\begin{equation}\n",
    "LogNormal(y|\\mu,\\sigma)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\frac{1}{y}exp(-\\frac{1}{2}\\frac{(log(y)-\\mu)^2}{sigma^2})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "* chi-square (Stan: y ~ chi_square(nu))\n",
    "\\begin{equation}\n",
    "ChiSquare(y|\\nu)=\\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)}y^{\\nu/2 -1}exp(-\\frac{1}{2}y)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "* inverse chi-square (Stan: y ~ inv_chi_square(nu))\n",
    "\\begin{equation}\n",
    "InvChiSquare(y|\\nu)=\\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)}y^{-\\nu/2 -1}exp(-\\frac{1}{2}\\frac{1}{y})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "* weibull (Stan: y ~ weibull(alpha, sigma))\n",
    "\\begin{equation}\n",
    "Weibull(y|\\alpha,\\sigma)=\\frac{\\alpha}{\\sigma}\n",
    "(\\frac{y}{\\sigma})^{\\alpha-1}exp(-(\\frac{y}{\\sigma})^{\\alpha})\n",
    "\\end{equation}\n",
    "\n",
    "These distributions are applicable for positive continuous data. In addition we wanted to see if normal distribution would be fit at all with the stan framework given that we think it should be inappropriate model for this type of data.\n",
    "\n",
    "* Normal (Stan: y ~ normal(mu, sigma))\n",
    "\\begin{equation}\n",
    "Normal(y|\\mu,\\sigma)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\frac{1}{y}exp(-\\frac{1}{2}\\frac{(y-\\mu)^2}{sigma^2})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Surprisingly the normal model did converge as R-hat values are 1.0 for all the parameters and generated quantities (can be seen in appendix A.2.). However, the psis-loo value of -9917  indicates that the model is bad if we compare to the good psis-loo values that the factory data analysis on week 8 of the course was yielding (in the ballpark of -130). \n",
    "\n",
    "The k-values for all the models indicate that psis-loo values indeed can be tursted. The best distribution turned out to be Weibull distribution with -2715 psis-loo value, while the worst is inverse chi-square with -15251 psis-loo value. The psis-loo of -2715 is still bad (relative to week 8), thus now the next step according to the Michael Betancourt workflow example is to look at the data and investigate on how can we improve our model.\n",
    "\n",
    "The raw data for small coins can be seen below as flattened and as individual coins.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"report_imgs/flat_prices.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "    <td><img src=\"report_imgs/ind_prices.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "</tr></table>\n",
    "\n",
    "Looking at the flattened data can be misleading to what the coins resemble individually, thus graph with individual raw prices is helpful to some extent. We can see a weird behaviour where Gas coin, given small market cap has quite big price magnitude in its' variation. However, differentiating between other coins is quite difficult from this perspective. Therefore, we decided to take logarithm of the raw price values in order to bring it down to more manageble scale.\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"report_imgs/sm_log_prices.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "    <td> <img src=\"report_imgs/big_log_prices.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "</tr></table>\n",
    "\n",
    "On the logarithm scale we can immediately see that prices tend to follow one of the two trends in price exchange, the cheap and expensive respectively. It might also seem like the marketcap affects somehow as into which category does the coin fall into. However, if we compare the graphs of big and small coins we can see that in both graphs the same phenomenon is happening, as coins with comparable marketcap value tend to be either cheap or expensive but not on the middle (we can see that coins with small market cap value would fall in between the coins with the big market cap value, thus it would be difficult to treat all the coins similarly). Therefore, we can safely assume that market capitalisation has no effect on to which category does the coin fall into - cheap or expensive.\n",
    "\n",
    "This type of phenomenon suggests that there should be mixture model for the prior as then the distribution of the individual coins would have the parameters constrained to one of the two peaks of the bimodal distribution. However, given the fact that we are fairly new with using the Stan framework, our lack in skill limited us in time to implement appropriate mixture model.\n",
    "\n",
    "What we could do however is split the small and big coins further into cheap and expensive sub-sets and analyse those sub-sets separately with the hierarchical priors that we have. However, given that logarithm gave us such contrast in the understanding the data, we decided to keep the data on the logarithm scale and apply different set of distributions which would be appropriate for the transformed data.\n",
    "\n",
    "#### Logarithm approach\n",
    "As the raw data approach yielded relatively bad results, we decided to proceed and implement the logarithm approach. As the data was transformed with the logarithm it no longer followed the property of being positive continuous, but rather now it resembled unbounded continuous data. Therefore, we needed new distributions which were appropriate for this task, as well as new prior. For the prior we decided to go with Normal distribution as we no longer had problems of positive valued data. The following distributions were chosen from the Stan documentation[5] in addition to Normal distribution.\n",
    "\n",
    "Distributions:\n",
    "\n",
    "* Cauchy (Stan: y ~ cauchy(mu, sigma))\n",
    "\\begin{equation}\n",
    "Cauchy(y|\\mu,\\sigma)=\\frac{1}{\\pi\\sigma}\\frac{1}{1+((y-\\mu)/\\sigma^2)}\n",
    "\\end{equation}\n",
    "\n",
    "* Laplace (Stan: y ~ double_exponential(mu, sigma))\n",
    "\\begin{equation}\n",
    "DoubleExponential(y|\\mu,\\sigma)=\\frac{1}{2\\sigma}exp(-\\frac{|y-\\mu|}{sigma})\n",
    "\\end{equation}\n",
    "\n",
    "* logistic (Stan: y ~ logistic(mu, sigma))\n",
    "\\begin{equation}\n",
    "Logistic(y|\\mu,\\sigma)=\\frac{1}{\\sigma}exp(-\\frac{y-\\mu}{sigma})(1+exp(-\\frac{y-\\mu}{\\sigma}))^{-2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The details of convergance can be seen in Appendix B.1. The code to run the stan files as well as code in stan files can be seen in Appendix B.2.\n",
    "\n",
    "The psis-loo values for each sub-set and distributions can be seen from below table, while the details are available in Appendix B.1. It is worth to note that in most cases the MCMC chains converged in the Stan model with total chain lengths of 4000 (rest parameters left as default), which is indicated by R hat values as they are less than 1.1. The one case which did not converge very well for parameters was Logistic distribution for coins with small market capitalisation in the cheap exchange price category. Specifically the mean parameter has R hat value of 1.41 which indicates some divergences in the chains. Lastly, variation for most of the distributions in cheap exchange price category for coins with big market capitalisation did not converge as all, however posterior draws seemed to be present, thus we decided to keep them.\n",
    "\n",
    "Overall the psis-loo values seem to be already better than they were in the first scenario and according to k-values (all below 0.5) the psis-loo values can be trusted.\n",
    "\n",
    "**Small coins**\n",
    "<table>\n",
    "    <tr>\n",
    "    <th>Distribution</th><th>Cheap</th><th>Expensive</th>\n",
    "    </tr>\n",
    "    <tr><td>Normal</td><td><strong>-1363</strong></td><td><strong>-2369</strong></td></tr>\n",
    "    <tr><td>Laplace</td><td>-1389</td><td>-2518</td></tr>\n",
    "    <tr><td>Logistic</td><td>-1371</td><td>-2416</td></tr>\n",
    "    <tr><td>Cauchy</td><td>-1526</td><td>-2790</td></tr>\n",
    "</table>\n",
    "\n",
    "**Big coins**\n",
    "<table>\n",
    "    <tr>\n",
    "    <th>Distribution</th><th>Cheap</th><th>Expensive</th>\n",
    "    </tr>\n",
    "    <tr><td >Normal</td><td><strong>-583</strong></td><td><strong>-1305</strong></td></tr>\n",
    "    <tr><td>Laplace</td><td>-604</td><td>-1411</td></tr>\n",
    "    <tr><td>Logistic</td><td>-591</td><td>-1336</td></tr>\n",
    "    <tr><td>Cauchy</td><td>-664</td><td>-1651</td></tr>\n",
    "</table>\n",
    "\n",
    "The best distributions for each category in the respective data sets are highlighted by bold typography. It appears that in every case normal distribution fits the price variation better than the others. This is surprisingly a contrary to the result achieved in the research paper \"A Statistical Analysis of Cryptocurrencies\"[3], where it is mentioned that normal distribution does not fit the exchange price of cryptocurrencies that well and instead they gave suggestions to use laplace and student-t. They might have used a bit different approach or the result might be due to the fact that they used data from different time-range. The time-range in the research paper is from July 2014 until February of 2017, while the data used in the project is from July 2017 for small coins and September 2017 for big coins until 29th November 2018. In addition the model evaluation in the paper was different from ours, as we were using psis-loo values.\n",
    "\n",
    "Below are posterior draws from the best distributions in each category, in order to see how our posterior distributions compare to the data. We can clearly see that the distributions are more organised than the data.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"report_imgs/post_small_cheap_norm.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "        <td> <img src=\"report_imgs/post_small_expensive_norm.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> <img src=\"report_imgs/post_big_cheap_norm.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "        <td> <img src=\"report_imgs/post_big_expensive_norm.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "The data that we have is more erratic and thus the bad psis-loo values when we are trying to fit the selected distributions. However, we can see from the table that normal distribution fits coins with bigger market capitalisation better than those with smaller market cap, as the psis-loo values are higher, which leaves to suggest that coins with bigger market capitalisation might follow the normal distribution better than those with smaller market cap.\n",
    "\n",
    "The results are still rather uncomfortable if we compare the psis-loo values to the week 8 factory example. The erratic behaviour that we would see when plotting one of the coins for example might be a reason to this. However, if we compare it to the logarithm of exchange prices to the price prediction data set, which have a year longer time period and thus many more data-points, we can see from below plots that the individual distribution of the coins would then also follow some bimodal distribution.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"report_imgs/adalog_i_prices_hist.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "    <td> <img src=\"report_imgs/prediction_log_prices.png\" style='width: 100%; object-fit: contain'/></td>\n",
    "</tr></table>\n",
    "\n",
    "**Note:** The frequency is actually count. And x-axis in both is logarithm of exchange price in USD.\n",
    "\n",
    "The mixture model resemblence for each coin suggests that we ought to change not only our hierarchical prior, but also the distributions that each price category (cheap/expensive) follow - a so to say mixture of mixtures. Given that we did not have previous experience with this and the lack of budget in terms of time we did not investigate the price variation further.\n",
    "\n",
    "Our intuition behind the phenomenon of individual coins having a mixture distribution is that we ignored the time parameter, and thus the two peaks represent the high and low moments in the cryptocurrency history. The exchange prices of coins were relatively cheap at first and then they raised to extreme amounts. Nowadays it is common to see that for instance bitcoin exchange price is falling down with extreme speed, thus contributing to the opposite peak of bimodal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price prediction\n",
    "\n",
    "Our hypothesis was that the price of cryptocurrencies can be predicted based on the price of bitcoin. And in order to get an idea of whether our hypothesis is correct or not we'll start by plotting the price of bitcoin against the price of other coins. We hope that we would be able to see some type of linear relationship by plotting this.\n",
    "\n",
    "![title](prediction/prices.png)\n",
    "\n",
    "The relationship between the prices is not perfectly linear but we can definitely see a strong linear relationship. This makes us hopefull that a simple linear model might very well be suitable to predict the price Ethereum, Litecoin, Ethereum Classic or DASH from the price of Bitcoin.  \n",
    "\n",
    "Next we will build a bayesian linear model for the prediction of the price using Stan. As we have the price data for all the coins all the way back to 2016, and don't have any prior data about the distributions we will let the likelihood function determine the predictive posterior distribution completely by setting a weak uniform prior.\n",
    "We'll use a gaussian model for the unexplained variance.\n",
    "\n",
    "Without looking much more into it, it seems that there is more volatility at high prices, which makes sense when taking the in to account the high volatility period at the start of 2017 when markets where booming.\n",
    "\n",
    "#### Gaussian linear model in Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data {\n",
      "    int<lower=0> N;\t// number of data points\n",
      "    int<lower=0> M;\t// number of prediction points\n",
      "    vector[N] x;\t// Coin 1\n",
      "    vector[N] y;\t// Coin 2\n",
      "    vector[M] xpreds;\t// Coin 1 hypothetical future prices\n",
      "}\n",
      "parameters {\n",
      "    real alpha;\n",
      "    real beta;\n",
      "    real<lower=0> sigma;\n",
      "}\n",
      "transformed parameters {\n",
      "    vector[N] mu;\n",
      "    mu = alpha + beta*x;\n",
      "}\n",
      "model {\n",
      "    alpha ~ normal(0, 1);\n",
      "    beta ~ normal(0, 1);\n",
      "    y ~ normal(mu, sigma);\n",
      "}\n",
      "generated quantities {\n",
      "    vector[M] ypreds; // Predictions based on hypothetical future prices of coin 1\n",
      "    vector[N] log_lik;\n",
      "    for(i in 1:M) {\n",
      "        ypreds[i] = normal_rng(alpha + beta*xpreds[i], sigma);\n",
      "    }\n",
      "    for (i in 1:N){\n",
      "        log_lik[i] = normal_lpdf(y[i] | mu[i], sigma);\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('prediction/lin_ex2.stan') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling the price of DASH as a function of the price of Bitcoin\n",
    "We'll select 5 hypotehtical future prices of bitcoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = pd.read_csv('data/selected/combined.csv', delimiter=\",\")\n",
    "n = data.shape[0]\n",
    "m = 5\n",
    "x = data[['BTC price(USD)']].values.flatten()[0:n]\n",
    "y = data[['DASH price(USD)']].values.flatten()[0:n]\n",
    "p = np.linspace(data[['BTC price(USD)']].min(), data[['BTC price(USD)']].max(), m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n"
     ]
    }
   ],
   "source": [
    "import stan_utility\n",
    "model = stan_utility.compile_model('prediction/lin_ex2.stan')\n",
    "model_data = dict(N=n,M=m,x=x,y=y,xpreds=p)\n",
    "fit = model.sampling(data=model_data, seed=74749)\n",
    "samples = fit.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Rhats and effective number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % of Rhat values below 1.01.\n",
      "100.0 % of n_eff values above 1300.\n"
     ]
    }
   ],
   "source": [
    "s = fit.summary()\n",
    "summary = pd.DataFrame(s['summary'], columns=s['summary_colnames'], index=s['summary_rownames'])\n",
    "c = summary.shape[0]\n",
    "rhat_c = sum(summary['Rhat'] < 1.01)\n",
    "n_eff_c = sum(summary['n_eff'] > 1300)\n",
    "print(\"%.1f %% of Rhat values below 1.01.\" % (rhat_c/c*100))\n",
    "print(\"%.1f %% of n_eff values above 1300.\" % (n_eff_c/c*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll check divergence a and treedepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 4000 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 4000 iterations ended with a divergence (0.0%)\n"
     ]
    }
   ],
   "source": [
    "stan_utility.check_treedepth(fit)\n",
    "stan_utility.check_div(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems so good so far and we'll continue to plot our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(14,7), sharex=True)\n",
    "preds = samples['ypreds'].T\n",
    "ax.scatter(data['BTC price(USD)'], data['DASH price(USD)'], alpha=0.5)\n",
    "ax.set_ylabel('DASH price')\n",
    "ax.set_xlabel('BTC price')\n",
    "ax.plot([p[0],p[-1]], [np.mean(preds[0]),np.mean(preds[-1])], c='r', alpha=1)\n",
    "for i in range(m):\n",
    "    ax.scatter([p[i]]*len(preds[i]),preds[i], alpha=0.1, c='g', marker=\"o\")\n",
    "    ax.scatter(p[i],np.mean(preds[i]), c='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we'll do Pareto smoothed importance sampling, so that we can compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loo: -5273.84\n",
      "   k<=0.5  0.5<k<=0.7  0.7<k\n",
      "0     856           0      0\n"
     ]
    }
   ],
   "source": [
    "from psis import psisloo\n",
    "loglik = samples['log_lik']\n",
    "loo, loos, ks = psisloo(loglik)\n",
    "print(\"Loo: %.2f\" % loo)\n",
    "\n",
    "ks_sum = [[\n",
    "    (ks <= 0.5).sum(),\n",
    "    sum([1 for k in ks if k > 0.5 and k <= 0.7]),\n",
    "    (ks > 0.7).sum()\n",
    "]]\n",
    "\n",
    "ks_df = pd.DataFrame(ks_sum, columns=[\"k<=0.5\", \"0.5<k<=0.7\", \"0.7<k\"])\n",
    "print(ks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student-t linear model in Stan\n",
    "\n",
    "We'll complete the same steps as above but for the Student's t-distribution. This could prove to be favourable as the Student's t-distribution has heavier tails and could thus fit better for the high variation at high prices.  \n",
    "\n",
    "The stan model is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Linear student-t model\n",
      "data {\n",
      "    int<lower=0> N; // number of data points\n",
      "    int<lower=0> M;\t// number of prediction points\n",
      "    vector[N] x; //\n",
      "    vector[N] y; //\n",
      "    vector[M] xpreds; // input location for prediction\n",
      "}\n",
      "parameters {\n",
      "    real alpha;\n",
      "    real beta;\n",
      "    real<lower=0> sigma;\n",
      "    real<lower=1, upper=80> nu;\n",
      "}\n",
      "transformed parameters {\n",
      "    vector[N] mu;\n",
      "    mu = alpha + beta*x;\n",
      "}\n",
      "model {\n",
      "    nu ~ gamma(2, 0.1); // Juarez and Steel(2010)\n",
      "    y ~ student_t(nu, mu, sigma);\n",
      "}\n",
      "generated quantities {\n",
      "    vector[M] ypreds;\n",
      "    vector[N] log_lik;\n",
      "    for(i in 1:M) {\n",
      "        ypreds[i] = normal_rng(alpha + beta*xpreds[i], sigma);\n",
      "    }\n",
      "    for (i in 1:N){\n",
      "        log_lik[i] = student_t_lpdf(y[i] | nu, mu[i], sigma);\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('prediction/lin_t.stan') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeating the process for the other coins\n",
    "Doing the same for the other big coins gives us the following predictions.\n",
    "![title](prediction/predicting_big_coins_gauss.png)\n",
    "\n",
    "The Student-t gives us the following result.\n",
    "![title](prediction/predicting_big_coins_t.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Pareto smoothed importance sampling values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian linear model\n",
    "| Data      | Loo       | k<=0.5 | 0.5<k<=0.7 |\n",
    "| :---------| ---------:|:------:|:----------:|\n",
    "| BTC v DASH|   1041.15 |     856|      0     |\n",
    "| BTC v LTC |   1038.67 |     856|      0     |\n",
    "| BTC v ETH |    749.24 |     856|      0     |\n",
    "| BTC v ETC |    681.05 |     856|      0     |\n",
    "\n",
    "##### Students t linear model\n",
    "| Data      | Loo       | k<=0.5 | 0.5<k<=0.7 |\n",
    "| :---------| ---------:|:------:|:----------:|\n",
    "| BTC v DASH|   1098.50 |     856|      0     |\n",
    "| BTC v LTC |   1148.05 |     856|      0     |\n",
    "| BTC v ETH |    747.74 |     856|      0     |\n",
    "| BTC v ETC |    779.93 |     856|      0     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Conclusions <a name=\"discussion\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a name=\"references\"></a>\n",
    "1. Coin Metrics, Data downloads. URL https://coinmetrics.io/data-downloads/ . (Online; accessed 27 November 2018)\n",
    "2. CoinMarketCap, Historical Snapshot - November 25, 2018. URL https://coinmarketcap.com/historical/20181125/ . (Online; accessed 30 November 2018)\n",
    "3. A Statistical Analysis of Cryptocurrencies. Stephen Chan, Jeffrey Chu, Saralees Nadarajah and Joerg Osterrieder, 31 May 2017. Journal of Risk and Financial Management.\n",
    "4. Michael Betancourt. Bayesian Workflow. URL: https://betanalpha.github.io/writing/ (Online; accessed 20 November 2018) (Link given by Aki Vehtari on one of the lectures)\n",
    "5. Stan distributions and helpful functions documentation. URL: https://mc-stan.org/docs/2_18/functions-reference/unbounded-continuous-distributions.html (Online; accessed 30 November 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix <a name=\"appendix\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1. Stan codes for price variation (positive continuous distributions):\n",
    "\n",
    "Data block for the different stan codes is the same, but parameters, model and thus generated quantities are somewhat different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Data Block same for all\n",
    "data {\n",
    "    int<lower=0> N; // number of data points\n",
    "    int<lower=0> K; // number of groups/coins\n",
    "    int<lower=1,upper=K> x[N]; // group/coin indicator\n",
    "    vector[N] y;\n",
    "    real low;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Chi-square\n",
    "parameters {\n",
    "    real<lower=low> mu0;\n",
    "    real<lower=low> sigma0;\n",
    "    vector<lower=low>[K] mu;\n",
    "}\n",
    "model {\n",
    "  mu ~ lognormal(mu0, sigma0);\n",
    "  y ~ chi_square(mu[x]);\n",
    "}\n",
    "generated quantities {\n",
    "  // Log_likelihood for psis_loo values\n",
    "  vector[N] log_lik;\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = chi_square_lpdf(y[i] | mu[x[i]]);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Inverse chi-square\n",
    "parameters {\n",
    "    real<lower=low> mu0;\n",
    "    real<lower=low> sigma0;\n",
    "    vector<lower=low>[K] mu;\n",
    "}\n",
    "model {\n",
    "  mu ~ lognormal(mu0, sigma0);\n",
    "  y ~ inv_chi_square(mu[x]);\n",
    "}\n",
    "generated quantities {\n",
    "  // Log_likelihood for psis_loo values\n",
    "  vector[N] log_lik;\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = inv_chi_square_lpdf(y[i] | mu[x[i]]);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Lognormal\n",
    "parameters {\n",
    "    real<lower=low> mu0;\n",
    "    real<lower=low> sigma0;\n",
    "    vector<lower=low>[K] mu;\n",
    "    real<lower=low> sigma;\n",
    "}\n",
    "model {\n",
    "  mu ~ lognormal(mu0, sigma0);\n",
    "  y ~ lognormal(mu[x], sigma);\n",
    "}\n",
    "generated quantities {\n",
    "  // Log_likelihood for psis_loo values\n",
    "  vector[N] log_lik;\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = lognormal_lpdf(y[i] | mu[x[i]], sigma);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Weibull\n",
    "parameters {\n",
    "    real<lower=low> mu0;\n",
    "    real<lower=low> sigma0;\n",
    "    vector<lower=low>[K] sigma;\n",
    "    real<lower=low> mu;\n",
    "}\n",
    "model {\n",
    "  sigma ~ lognormal(mu0, sigma0);\n",
    "  y ~ weibull(mu, sigma[x]);\n",
    "}\n",
    "generated quantities {\n",
    "  // Log_likelihood for psis_loo values\n",
    "  vector[N] log_lik;\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = weibull_lpdf(y[i] | mu, sigma[x[i]]);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Price variation convergence results (positive continuous):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm:\n",
    "               mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             5.74    0.09   3.99   0.47   3.25    5.2   7.57  14.09   1863    1.0\n",
    "sigma0          9.59    0.13    5.4   4.71   6.73   8.35  10.89  21.65   1634    1.0\n",
    "mu[1]           0.05  3.7e-3   0.26  -0.46  -0.14   0.05   0.22   0.56   4875    1.0\n",
    "mu[2]          18.81  4.0e-3   0.27  18.29  18.63  18.81  18.99  19.34   4478    1.0\n",
    "mu[3]           3.62  3.7e-3   0.27    3.1   3.45   3.62    3.8   4.14   5228    1.0\n",
    "mu[4]           2.24  4.2e-3   0.27    1.7   2.06   2.25   2.42   2.77   4322    1.0\n",
    "mu[5]           4.72  4.1e-3   0.27   4.19   4.53   4.72    4.9   5.24   4380    1.0\n",
    "mu[6]           0.04  4.1e-3   0.27   -0.5  -0.14   0.04   0.23   0.57   4485    1.0\n",
    "sigma           6.09  1.2e-3   0.08   5.94   6.04   6.09   6.14   6.25   4560    1.0\n",
    "log_lik[1-3072]\t\t\t\t\t\t\t\t                           3500-5000 1.0\n",
    "_____________________________________________________________________________________\n",
    "chi-square:\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             1.03    0.02   0.72   0.07   0.55   0.93   1.36   2.75   2244    1.0\n",
    "sigma0          1.84    0.02   0.89    0.9   1.28   1.61   2.12   4.06   2214    1.0\n",
    "mu[1]           0.48  3.1e-4   0.02   0.44   0.46   0.48   0.49   0.52   4357    1.0\n",
    "mu[2]           14.6  3.5e-3   0.23  14.14  14.44  14.59  14.75  15.07   4346    1.0\n",
    "mu[3]            3.8  1.7e-3   0.11   3.59   3.72   3.79   3.87   4.01   3917    1.0\n",
    "mu[4]            2.4  1.2e-3   0.08   2.25   2.34   2.39   2.45   2.55   4352    1.0\n",
    "mu[5]           4.94  1.9e-3   0.12    4.7   4.86   4.94   5.03   5.19   4162    1.0\n",
    "mu[6]           0.45  2.9e-4   0.02   0.41   0.44   0.45   0.46   0.49   4222    1.0\n",
    "log_lik[1-3072]\t\t\t\t\t\t\t\t                           3500-5000 1.0\n",
    "_____________________________________________________________________________________\n",
    "inv chi-square:\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             1.59    0.02   1.02   0.12   0.87   1.46   2.12   3.85   2580    1.0\n",
    "sigma0          2.72    0.03   1.24   1.37   1.94    2.4   3.13   5.96   2057    1.0\n",
    "mu[1]          43.09  5.6e-3   0.41  42.28  42.82  43.09  43.38   43.9   5250    1.0\n",
    "mu[2]           0.63  4.4e-4   0.03   0.58   0.62   0.63   0.65   0.69   3589    1.0\n",
    "mu[3]            1.1  7.1e-4   0.04   1.01   1.07    1.1   1.13   1.18   3725    1.0\n",
    "mu[4]           1.49  7.9e-4   0.05   1.38   1.45   1.49   1.53    1.6   4838    1.0\n",
    "mu[5]           0.96  5.6e-4   0.04   0.88   0.93   0.96   0.98   1.03   4619    1.0\n",
    "mu[6]           57.0  6.4e-3   0.46   56.1  56.67   57.0  57.31  57.88   5142    1.0\n",
    "log_lik[1-3072]\t\t\t\t\t\t\t\t                           3500-5000 1.0\n",
    "_____________________________________________________________________________________\n",
    "weibull:\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             1.22    0.02   1.26   0.04   0.43   0.91   1.63   4.17   3041    1.0\n",
    "sigma0          3.76    0.04   1.92   1.84   2.64   3.29   4.31   8.67   1970    1.0\n",
    "sigma[1]        0.03  1.6e-5 9.9e-4   0.03   0.03   0.03   0.03   0.03   4052    1.0\n",
    "sigma[2]       20.34    0.01   0.71   19.0  19.85  20.33  20.81  21.76   4183    1.0\n",
    "sigma[3]         3.9  2.1e-3   0.13   3.66   3.82    3.9   3.99   4.17   3747    1.0\n",
    "sigma[4]        2.49  1.4e-3   0.09   2.32   2.43   2.49   2.55   2.68   4256    1.0\n",
    "sigma[5]        4.97  2.8e-3   0.18   4.64   4.85   4.97   5.08   5.32   3957    1.0\n",
    "sigma[6]        0.04  2.3e-5 1.4e-3   0.04   0.04   0.04   0.04   0.04   3755    1.0\n",
    "mu               1.3  3.0e-4   0.02   1.27   1.29    1.3   1.32   1.34   3498    1.0\n",
    "log_lik[1-3072]\t\t\t\t\t\t\t\t                           3500-5000 1.0\n",
    "_____________________________________________________________________________________\n",
    "lognormal:\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             3.57    0.23   5.62   0.09    0.8   1.79   4.03  18.72    620    1.0\n",
    "sigma0         15.42    0.83  15.72   4.06   7.13  10.49  17.65   57.7    356   1.01\n",
    "mu[1]         4.8e-4  2.5e-5 1.2e-39.5e-25 6.0e-8 2.3e-5 3.9e-4 3.9e-3   2231    1.0\n",
    "mu[2]           2.61  3.3e-3   0.11    2.4   2.54   2.61   2.69   2.82   1023    1.0\n",
    "mu[3]           1.04  3.1e-3   0.11   0.83   0.96   1.04   1.11   1.26   1244    1.0\n",
    "mu[4]           0.38  3.4e-3   0.11   0.16    0.3   0.38   0.45    0.6   1032    1.0\n",
    "mu[5]           1.38  2.9e-3    0.1   1.19   1.31   1.38   1.45   1.57   1238    1.0\n",
    "mu[6]         4.7e-4  2.1e-5 1.1e-32.5e-23 2.7e-8 1.6e-5 3.2e-4 3.9e-3   2884    1.0\n",
    "sigma           2.39  9.3e-4   0.03   2.33   2.37   2.39   2.41   2.45   1045    1.0\n",
    "log_lik[1-3072]\t\t\t\t\t\t\t\t                           3500-5000 1.0\n",
    "\n",
    "Psis-Loo and k values:\n",
    "norm.stan\n",
    "psis-loo: -9917.198119593282 \n",
    "K-VALUES:\n",
    " (-inf;0.5] & 3070 & 99.93489583333333\n",
    " (0.5;0.7] & 2 & 0.06510416666666667\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "______________________________________________\n",
    "chi.stan\n",
    "psis-loo: -4366.419948382528\n",
    "K-VALUES:\n",
    " (-inf;0.5] & 3072 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "______________________________________________\n",
    "inv_chi.stan\n",
    "psis-loo: -15251.781472074534\n",
    "K-VALUES:\n",
    " (-inf;0.5] & 3072 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "______________________________________________\n",
    "weibull.stan\n",
    "psis-loo: -2715.379821859008\n",
    "K-VALUES:\n",
    " (-inf;0.5] & 3072 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "______________________________________________\n",
    "lognormal.stan\n",
    "psis-loo: -5849.437259681001\n",
    "K-VALUES:\n",
    " (-inf;0.5] & 3072 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "______________________________________________\n",
    "Effective parameters: \n",
    "norm:\n",
    " p_eff:9815.832776137628\n",
    "chi-square:\n",
    " p_eff:4318.562791844692\n",
    "inv-chi:\n",
    " p_eff:14965.007978940113\n",
    "weibull:\n",
    " p_eff:2701.164757074006\n",
    "lognormal:\n",
    " p_eff:5809.290561622702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1. Price variation convergence results (unbounded continuous):\n",
    "\n",
    "#### SMALL coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cheap_norm\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0            6.4e9   5.6e9 5.5e10-1.5e10 -1.4e8  6.2e4  1.5e8 1.3e11     96   1.03\n",
    "sigma0        7.3e11  5.7e11 3.3e13  2.8e5  3.0e7  3.5e8  4.5e9 5.2e11   3326    1.0\n",
    "mu[1]          -3.74  9.9e-4   0.04  -3.82  -3.77  -3.74  -3.71  -3.66   1673    1.0\n",
    "mu[2]          -4.03  8.2e-4   0.04   -4.1  -4.05  -4.03   -4.0  -3.95   2257    1.0\n",
    "sigma           0.91  4.1e-4   0.02   0.88    0.9   0.91   0.93   0.96   2382    1.0\n",
    "ypred[1]       -3.73    0.01   0.92  -5.54  -4.36  -3.73  -3.12  -1.95   7863    1.0\n",
    "ypred[2]       -4.02    0.01    0.9  -5.75  -4.64  -4.03  -3.41  -2.23   7743    1.0\n",
    "log_lik[1]      -0.9  5.4e-4   0.03  -0.95  -0.91   -0.9  -0.88  -0.85   2259    1.0\n",
    "log_lik[2]     -2.26  1.6e-3   0.08  -2.43  -2.31  -2.26  -2.21   -2.1   2759    1.0\n",
    "log_lik[3]     -0.88  5.2e-4   0.02  -0.93  -0.89  -0.88  -0.86  -0.83   2287    1.0\n",
    "...\n",
    "log_lik[1022]  -1.53  1.0e-3   0.05  -1.63  -1.56  -1.53  -1.49  -1.43   2442    1.0\n",
    "log_lik[1023]  -0.99  6.6e-4   0.03  -1.05  -1.01  -0.99  -0.97  -0.93   2027    1.0\n",
    "log_lik[1024]  -1.19  8.0e-4   0.04  -1.27  -1.22  -1.19  -1.17  -1.12   2147    1.0\n",
    "lp__          -440.7    1.12   3.81 -448.2 -443.3 -440.7 -438.1 -433.3     11   1.22\n",
    "\n",
    "small_cheap_laplace\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0           -4.3e7   6.9e7  6.6e8 -1.2e9 -3.5e6  -1034  6.1e6  9.9e8     91   1.02\n",
    "sigma0         1.5e9   4.1e8 1.3e10 3422.0  2.3e5  1.0e7  2.8e8  9.6e9    998   1.01\n",
    "mu[1]          -3.72  4.8e-4   0.03  -3.78  -3.74  -3.72  -3.71  -3.67   3037    1.0\n",
    "mu[2]          -4.19  6.1e-4   0.04  -4.25  -4.21  -4.19  -4.16   -4.1   3949    1.0\n",
    "sigma           0.71  3.9e-4   0.02   0.67    0.7   0.71   0.73   0.76   3161    1.0\n",
    "ypred[1]       -3.74    0.01   1.03  -6.01  -4.24  -3.72  -3.21  -1.62   7758    1.0\n",
    "ypred[2]       -4.19    0.01   1.01  -6.31  -4.68  -4.19  -3.69  -2.06   7987    1.0\n",
    "log_lik[1]     -0.85  7.4e-4   0.04  -0.92  -0.88  -0.85  -0.82  -0.76   2923    1.0\n",
    "log_lik[2]      -2.3 10.0e-4   0.06  -2.43  -2.34   -2.3  -2.26  -2.19   3734    1.0\n",
    "log_lik[3]     -0.78  7.6e-4   0.04  -0.85  -0.81  -0.78  -0.75  -0.69   2908    1.0\n",
    "...\n",
    "log_lik[1022]  -1.65  8.6e-4   0.05  -1.76  -1.68  -1.64  -1.61  -1.55   3939    1.0\n",
    "log_lik[1023]   -1.1  7.0e-4   0.04  -1.17  -1.13   -1.1  -1.08  -1.02   2951    1.0\n",
    "log_lik[1024]  -1.22  8.5e-4   0.05  -1.34  -1.26  -1.22  -1.18  -1.13   3954    1.0\n",
    "lp__          -694.2    2.03   4.51 -701.9 -697.9 -694.5 -690.7 -685.8      5   1.41\n",
    "\n",
    "small_cheap_logistic\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0           -3.8e7   7.9e7  2.9e8 -1.1e9 -6.0e5 385.89  2.1e6  5.2e8     14   1.49\n",
    "sigma0         7.4e8   5.5e8  8.6e9 568.89  9.4e4  3.1e6  5.8e7  4.3e9    250   1.02\n",
    "mu[1]          -3.74  1.6e-3   0.04  -3.82  -3.77  -3.74  -3.72  -3.67    552   1.02\n",
    "mu[2]          -4.05  6.1e-3   0.05  -4.13  -4.09  -4.05  -4.02  -3.96     59   1.07\n",
    "sigma           0.52  2.8e-4   0.01    0.5   0.51   0.52   0.53   0.55   2144   1.01\n",
    "ypred[1]       -3.73    0.01   0.94  -5.62  -4.31  -3.74  -3.15   -1.8   8314    1.0\n",
    "ypred[2]       -4.06    0.01   0.95  -5.99  -4.62  -4.06  -3.49  -2.16   7387    1.0\n",
    "log_lik[1]     -0.83  1.4e-3   0.03  -0.89  -0.85  -0.84  -0.81  -0.78    411   1.02\n",
    "log_lik[2]     -2.37    0.01   0.09  -2.56  -2.44  -2.38   -2.3  -2.22     62   1.07\n",
    "log_lik[3]     -0.81  1.3e-3   0.03  -0.86  -0.82  -0.81  -0.79  -0.75    490   1.02\n",
    "...\n",
    "log_lik[1022]  -1.62  9.3e-3   0.07  -1.76  -1.67  -1.62  -1.57   -1.5     59   1.07\n",
    "log_lik[1023]  -0.97  1.7e-3   0.03  -1.03  -0.99  -0.97  -0.94   -0.9    395   1.02\n",
    "log_lik[1024]  -1.22  7.0e-3   0.06  -1.33  -1.25  -1.22  -1.17  -1.12     64   1.07\n",
    "lp__           -1384    2.13   4.67  -1392  -1388  -1384  -1381  -1375      5   1.49\n",
    "\n",
    "small_cheap_cauchy\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0           -2.5e9   1.8e9 1.3e10-4.4e10 -5.6e7  6.2e4  8.5e7  3.8e9     49   1.09\n",
    "sigma0        5.7e10  3.5e10 2.2e12  2.5e5  1.5e7  1.8e8  1.5e9 1.3e11   3886    1.0\n",
    "mu[1]          -3.73  6.7e-4   0.03  -3.79  -3.75  -3.73  -3.72  -3.68   1763    1.0\n",
    "mu[2]          -4.14  1.0e-3   0.05  -4.23  -4.17  -4.14   -4.1  -4.04   2204    1.0\n",
    "sigma           0.52  6.6e-4   0.02   0.48   0.51   0.52   0.54   0.56   1087    1.0\n",
    "ypred[1]       -6.14     2.8 250.69  -9.44  -4.24  -3.73  -3.21   3.15   8009    1.0\n",
    "ypred[2]       -3.44    0.55  49.13 -10.91  -4.67  -4.14  -3.62   2.23   7991    1.0\n",
    "log_lik[1]     -0.85  1.1e-3   0.05  -0.95  -0.88  -0.85  -0.82  -0.75   2060    1.0\n",
    "log_lik[2]     -2.65  1.3e-3   0.06  -2.77  -2.69  -2.65   -2.6  -2.52   2331    1.0\n",
    "log_lik[3]     -0.76  1.1e-3   0.05  -0.86   -0.8  -0.76  -0.73  -0.67   2108    1.0\n",
    "...\n",
    "log_lik[1022]  -1.99  1.6e-3   0.08  -2.14  -2.04  -1.99  -1.94  -1.84   2393    1.0\n",
    "log_lik[1023]  -1.18  1.3e-3   0.05  -1.29  -1.22  -1.18  -1.15  -1.07   1649    1.0\n",
    "log_lik[1024]  -1.47  1.8e-3   0.09  -1.64  -1.52  -1.46  -1.41  -1.29   2332    1.0\n",
    "lp__          -372.1    0.84   3.77 -379.3 -374.6 -372.3 -369.5 -364.9     20   1.14\n",
    "\n",
    "small_expensive_norm\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             1.34    0.03   1.27  -1.17    0.9   1.36   1.82   3.56   1555    1.0\n",
    "sigma0           1.9    0.05   1.91   0.59   0.96   1.35    2.1   6.66   1768    1.0\n",
    "mu[1]           2.61  4.4e-4   0.04   2.54   2.59   2.61   2.63   2.68   6490    1.0\n",
    "mu[2]           1.05  4.0e-4   0.03   0.98   1.03   1.05   1.07   1.12   7241    1.0\n",
    "mu[3]            0.4  4.0e-4   0.03   0.34   0.38    0.4   0.43   0.47   7142    1.0\n",
    "mu[4]           1.38  4.0e-4   0.03   1.32   1.36   1.38   1.41   1.45   7117    1.0\n",
    "sigma           0.77  1.4e-4   0.01   0.75   0.76   0.77   0.78   0.79   7278    1.0\n",
    "ypred[1]        2.62  8.4e-3   0.76   1.11   2.12   2.62   3.12   4.12   8292    1.0\n",
    "ypred[2]        1.05  8.4e-3   0.76  -0.45   0.55   1.05   1.57   2.52   8282    1.0\n",
    "ypred[3]         0.4  8.6e-3   0.77  -1.17  -0.12   0.41   0.93   1.93   8065    1.0\n",
    "ypred[4]        1.39  8.8e-3   0.77  -0.12   0.87    1.4   1.91   2.87   7690    1.0\n",
    "log_lik[1]     -4.16  1.9e-3   0.15  -4.47  -4.26  -4.16  -4.05  -3.86   6415    1.0\n",
    "log_lik[2]     -0.66  2.0e-4   0.02   -0.7  -0.67  -0.66  -0.65  -0.63   7095    1.0\n",
    "log_lik[3]     -1.14  5.1e-4   0.04  -1.23  -1.17  -1.14  -1.11  -1.06   7122    1.0\n",
    "...\n",
    "log_lik[2046]  -2.11  9.4e-4   0.08  -2.27  -2.16  -2.11  -2.05  -1.95   7411    1.0\n",
    "log_lik[2047]  -2.57  1.2e-3    0.1  -2.77  -2.64  -2.57  -2.51  -2.39   7035    1.0\n",
    "log_lik[2048]  -1.97  9.0e-4   0.08  -2.12  -2.02  -1.97  -1.92  -1.82   7035    1.0\n",
    "lp__          -487.4    0.04   2.16 -492.7 -488.6 -487.0 -485.8 -484.4   2553    1.0\n",
    "\n",
    "small_expensive_laplace\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             1.08    0.31   3.35  -1.97   0.81   1.37   1.89   3.94    114   1.04\n",
    "sigma0          2.76    0.48   5.88   0.73   1.15   1.62   2.49  11.09    148   1.03\n",
    "mu[1]           2.86  4.5e-4   0.04   2.78   2.83   2.86   2.88   2.93   7294    1.0\n",
    "mu[2]           1.13  3.6e-4   0.03   1.07   1.11   1.13   1.15   1.19   7057    1.0\n",
    "mu[3]           0.17  5.9e-4   0.05   0.08   0.13   0.17    0.2   0.27   7327    1.0\n",
    "mu[4]           1.41  3.7e-4   0.03   1.34   1.39   1.41   1.43   1.47   7206    1.0\n",
    "sigma           0.63  1.6e-4   0.01    0.6   0.62   0.63   0.64   0.66   7728    1.0\n",
    "ypred[1]        2.85  9.7e-3   0.88   0.97   2.41   2.86   3.29   4.71   8277    1.0\n",
    "ypred[2]        1.13    0.01   0.89  -0.79   0.68   1.14   1.58   3.02   7930    1.0\n",
    "ypred[3]        0.17  9.8e-3   0.87  -1.68  -0.25   0.16    0.6   2.03   7952    1.0\n",
    "ypred[4]        1.42    0.01    0.9  -0.44    1.0   1.42   1.86    3.3   7985    1.0\n",
    "log_lik[1]     -3.86  9.6e-4   0.08  -4.02  -3.91  -3.86   -3.8  -3.69   7514    1.0\n",
    "log_lik[2]      -0.5  5.9e-4   0.05   -0.6  -0.53   -0.5  -0.47   -0.4   7277    1.0\n",
    "log_lik[3]     -1.06  9.5e-4   0.08  -1.23  -1.11  -1.05   -1.0  -0.91   7312    1.0\n",
    "...\n",
    "log_lik[2046]  -2.44  6.5e-4   0.06  -2.55  -2.48  -2.44   -2.4  -2.33   7111    1.0\n",
    "log_lik[2047]  -2.25  9.6e-4   0.08  -2.42   -2.3  -2.25  -2.19   -2.1   7548    1.0\n",
    "log_lik[2048]  -2.25  6.3e-4   0.05  -2.35  -2.28  -2.25  -2.21  -2.14   7533    1.0\n",
    "lp__           -1098    0.12   2.31  -1104  -1099  -1098  -1097  -1095    398   1.01\n",
    "\n",
    "small_expensive_logistic\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             1.35    0.04   1.54  -1.62   0.85   1.36   1.86   4.05   1357    1.0\n",
    "sigma0          2.16    0.07   2.63   0.63   1.02   1.47    2.3   7.82   1284    1.0\n",
    "mu[1]           2.68  4.5e-4   0.04   2.61   2.65   2.68    2.7   2.75   6792    1.0\n",
    "mu[2]           1.05  4.0e-4   0.03   0.98   1.03   1.05   1.07   1.12   7338    1.0\n",
    "mu[3]           0.35  4.4e-4   0.04   0.27   0.32   0.35   0.37   0.42   7398    1.0\n",
    "mu[4]           1.38  3.7e-4   0.03   1.31   1.35   1.38    1.4   1.44   7703    1.0\n",
    "sigma           0.45  9.4e-5 8.2e-3   0.43   0.44   0.45   0.45   0.47   7654    1.0\n",
    "ypred[1]        2.67  9.1e-3   0.83   0.97   2.18   2.67   3.16   4.36   8200    1.0\n",
    "ypred[2]        1.03  9.1e-3   0.81  -0.63   0.55   1.04   1.52   2.65   8016    1.0\n",
    "ypred[3]        0.35  9.3e-3   0.81  -1.27  -0.14   0.35   0.85   2.02   7570    1.0\n",
    "ypred[4]        1.38  9.1e-3   0.81  -0.23   0.87   1.38   1.86   2.98   7839    1.0\n",
    "log_lik[1]      -3.9  1.3e-3   0.11   -4.1  -3.97   -3.9  -3.83  -3.69   6726    1.0\n",
    "log_lik[2]      -0.6  2.3e-4   0.02  -0.64  -0.61   -0.6  -0.58  -0.56   7468    1.0\n",
    "log_lik[3]     -1.14  6.4e-4   0.06  -1.25  -1.18  -1.14   -1.1  -1.03   7398    1.0\n",
    "...\n",
    "log_lik[2046]  -2.22  8.7e-4   0.07  -2.37  -2.27  -2.22  -2.17  -2.08   7342    1.0\n",
    "log_lik[2047]   -2.5  9.7e-4   0.09  -2.67  -2.56   -2.5  -2.44  -2.34   7713    1.0\n",
    "log_lik[2048]  -2.08  7.7e-4   0.07  -2.21  -2.12  -2.08  -2.03  -1.94   7929    1.0\n",
    "lp__           -2416    0.05   2.21  -2422  -2418  -2416  -2415  -2413   2144    1.0\n",
    "\n",
    "small_expensive_cauchy\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             1.25    0.08   2.08  -2.29   0.73   1.35   1.94   4.28    747    1.0\n",
    "sigma0          2.61    0.14   4.47   0.75   1.23   1.77   2.72   9.46   1005    1.0\n",
    "mu[1]           2.89  4.0e-4   0.03   2.82   2.87   2.89   2.91   2.96   7083    1.0\n",
    "mu[2]           1.11  3.9e-4   0.03   1.04   1.09   1.11   1.13   1.18   7501    1.0\n",
    "mu[3]           0.05  4.9e-4   0.04  -0.03   0.02   0.05   0.08   0.14   7492    1.0\n",
    "mu[4]           1.39  3.3e-4   0.03   1.33   1.37   1.39   1.41   1.45   7387    1.0\n",
    "sigma           0.47  1.7e-4   0.01   0.44   0.46   0.47   0.48    0.5   6933    1.0\n",
    "ypred[1]        2.35     0.6  53.98  -3.03   2.42   2.88   3.33   8.27   8007    1.0\n",
    "ypred[2]        1.04     0.4  35.42  -4.99   0.65   1.11   1.58   7.21   8036    1.0\n",
    "ypred[3]      -38.86   39.04 3493.9  -5.69  -0.42   0.05   0.54   6.09   8008    1.0\n",
    "ypred[4]        1.72    0.51  45.17  -5.42   0.92   1.38   1.83   7.87   7985    1.0\n",
    "log_lik[1]     -3.62  5.1e-4   0.04   -3.7  -3.65  -3.62  -3.59  -3.53   6670    1.0\n",
    "log_lik[2]     -0.49  5.2e-4   0.05  -0.59  -0.52  -0.49  -0.46  -0.41   8048    1.0\n",
    "log_lik[3]     -0.94  1.1e-3   0.09  -1.13   -1.0  -0.94  -0.88  -0.77   7386    1.0\n",
    "...\n",
    "log_lik[2046]  -2.64  6.4e-4   0.05  -2.74  -2.68  -2.64  -2.61  -2.54   6639    1.0\n",
    "log_lik[2047]  -2.34  6.8e-4   0.06  -2.46  -2.38  -2.34   -2.3  -2.22   8355    1.0\n",
    "log_lik[2048]  -2.48  5.5e-4   0.05  -2.57  -2.51  -2.48  -2.45  -2.39   7251    1.0\n",
    "lp__          -445.8    0.05   2.23 -451.2 -446.9 -445.4 -444.2 -442.7   1967    1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap norm\n",
    "psis-loo: -1362.8579714727484\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1024 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:1303.4201772321528\n",
    "\n",
    "cheap laplace\n",
    "psis-loo: -1388.7278311372618\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1024 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:1328.9902476149828\n",
    "\n",
    "cheap logistic\n",
    "psis-loo: -1370.5909297089192\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1024 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:1310.6457647104382\n",
    "\n",
    "cheap cauchy\n",
    "psis-loo: -1526.4111076212141\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1024 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:1460.6464987647012\n",
    "\n",
    "expensive norm\n",
    "psis-loo: -2368.8622836308004\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 2048 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:2315.3510146880626\n",
    "\n",
    "expensive laplace\n",
    "psis-loo: -2518.462464130536\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 2048 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:2467.8075769856764\n",
    "\n",
    "expensive logistic\n",
    "psis-loo: -2415.802829512738\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 2048 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:2363.9752340041196\n",
    "\n",
    "expensive cauchy\n",
    "psis-loo: -2789.849802503597\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 2048 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:2739.4458497175733"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIG coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_cheap_norm.stan\n",
    "               mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0         -1.6e13  1.5e13 5.1e13-1.2e14-5.8e13 5.4e11 3.6e12 9.9e13     12   1.45\n",
    "sigma0          inf     nan    inf 1.6e20 4.6e832.9e1544.7e2292.9e300    nan    nan\n",
    "mu[1]          -2.0  9.3e-4   0.05  -2.09  -2.03   -2.0  -1.97  -1.91   2481    1.0\n",
    "sigma          0.96  6.8e-4   0.03   0.89   0.93   0.95   0.98   1.02   2467    1.0\n",
    "ypred[1]      -2.02    0.01   0.95  -3.92  -2.65  -2.01  -1.37  -0.17   7343    1.0\n",
    "log_lik[1]    -2.71  2.5e-3   0.13  -2.98  -2.79  -2.71  -2.62  -2.47   2647    1.0\n",
    "log_lik[2]    -2.46  2.2e-3   0.11   -2.7  -2.54  -2.46  -2.39  -2.25   2656    1.0\n",
    "log_lik[3]    -2.38  2.1e-3   0.11   -2.6  -2.45  -2.38   -2.3  -2.18   2660    1.0\n",
    "...\n",
    "log_lik[423]  -1.85  1.5e-3   0.07   -2.0  -1.89  -1.84  -1.79  -1.71   2633    1.0\n",
    "log_lik[424]  -1.81  1.4e-3   0.07  -1.96  -1.86  -1.81  -1.76  -1.68   2633    1.0\n",
    "log_lik[425]  -1.61  1.2e-3   0.06  -1.74  -1.65  -1.61  -1.57   -1.5   2617    1.0\n",
    "lp__         -191.9    0.02   1.03 -194.6 -192.3 -191.6 -191.2 -190.9   1766    1.0\n",
    "\n",
    "big_cheap_laplace.stan\n",
    "               mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0         -1.4e13  2.3e13 3.8e13-1.1e14-4.1e12 2.1e12 7.1e12 2.3e13      3   3.19\n",
    "sigma0          inf     nan    inf 2.4e20 1.5e852.1e1592.4e2333.5e301    nan    nan\n",
    "mu[1]         -1.94  8.7e-4   0.04  -2.03  -1.97  -1.94  -1.91  -1.86   2431    1.0\n",
    "sigma          0.76  7.5e-4   0.04    0.7   0.74   0.76   0.79   0.84   2426    1.0\n",
    "ypred[1]      -1.94    0.01   1.07  -4.22  -2.46  -1.93   -1.4   0.28   7497    1.0\n",
    "log_lik[1]     -2.9  1.9e-3   0.09  -3.08  -2.96   -2.9  -2.84  -2.72   2355    1.0\n",
    "log_lik[2]    -2.74  1.8e-3   0.09  -2.91  -2.79  -2.73  -2.68  -2.57   2351    1.0\n",
    "log_lik[3]    -2.68  1.7e-3   0.08  -2.84  -2.73  -2.67  -2.62  -2.51   2349    1.0\n",
    "...\n",
    "log_lik[423]  -2.25  1.4e-3   0.07  -2.39  -2.29  -2.25   -2.2  -2.11   2345    1.0\n",
    "log_lik[424]  -2.22  1.4e-3   0.07  -2.35  -2.26  -2.22  -2.17  -2.08   2346    1.0\n",
    "log_lik[425]  -2.02  1.3e-3   0.06  -2.15  -2.07  -2.03  -1.98   -1.9   2355    1.0\n",
    "lp__         -309.4    0.02   0.98 -312.1 -309.8 -309.1 -308.7 -308.5   2124    1.0\n",
    "\n",
    "big_cheap_logistic.stan\n",
    "               mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0         -5.5e13  2.6e13 5.7e13-1.8e14-8.7e13-4.8e13-7.8e12 1.6e13      5   2.28\n",
    "sigma0          inf     nan    inf 2.6e21 3.5e831.9e1561.9e2303.7e300    nan    nan\n",
    "mu[1]         -1.98  9.1e-4   0.05  -2.07  -2.01  -1.98  -1.95  -1.89   2592    1.0\n",
    "sigma          0.55  4.4e-4   0.02   0.51   0.54   0.55   0.57    0.6   2526    1.0\n",
    "ypred[1]      -1.98    0.01   1.01  -4.02  -2.59  -1.99  -1.38   0.11   7297    1.0\n",
    "log_lik[1]    -2.83  2.3e-3   0.12  -3.06   -2.9  -2.82  -2.75  -2.61   2570    1.0\n",
    "log_lik[2]    -2.61  2.1e-3   0.11  -2.83  -2.68  -2.61  -2.54  -2.42   2578    1.0\n",
    "log_lik[3]    -2.54  2.0e-3    0.1  -2.75  -2.61  -2.54  -2.47  -2.35   2581    1.0\n",
    "...\n",
    "log_lik[423]  -2.02  1.6e-3   0.08  -2.19  -2.07  -2.02  -1.96  -1.87   2602    1.0\n",
    "log_lik[424]  -1.99  1.6e-3   0.08  -2.15  -2.04  -1.98  -1.93  -1.83   2604    1.0\n",
    "log_lik[425]  -1.77  1.4e-3   0.07  -1.91  -1.82  -1.77  -1.72  -1.64   2611    1.0\n",
    "lp__         -591.1    0.02   0.99 -593.7 -591.5 -590.8 -590.4 -590.1   2223    1.0\n",
    "\n",
    "big_cheap_cauchy.stan\n",
    "               mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0         -3.0e12  1.6e13 5.9e13-1.6e14-1.8e13 1.2e12 1.1e13 1.0e14     14    1.4\n",
    "sigma0          inf     nan    inf 7.7e21 7.7e881.8e1639.8e2364.5e301    nan    nan\n",
    "mu[1]         -1.95 10.0e-4   0.05  -2.04  -1.98  -1.95  -1.92  -1.86   2092    1.0\n",
    "sigma          0.58  6.9e-4   0.04   0.51   0.55   0.57    0.6   0.65   2729    1.0\n",
    "ypred[1]      -1.79    0.34  29.87  -9.95  -2.56  -1.95  -1.36   6.41   7931    1.0\n",
    "log_lik[1]    -3.05  1.4e-3   0.07  -3.19   -3.1  -3.05  -3.01  -2.92   2404    1.0\n",
    "log_lik[2]    -2.93  1.4e-3   0.07  -3.06  -2.97  -2.93  -2.88  -2.79   2367    1.0\n",
    "log_lik[3]    -2.88  1.4e-3   0.07  -3.02  -2.93  -2.88  -2.83  -2.74   2352    1.0\n",
    "...\n",
    "log_lik[423]  -2.51  1.5e-3   0.07  -2.65  -2.56  -2.51  -2.46  -2.37   2233    1.0\n",
    "log_lik[424]  -2.48  1.5e-3   0.07  -2.62  -2.53  -2.48  -2.43  -2.34   2224    1.0\n",
    "log_lik[425]  -2.29  1.6e-3   0.07  -2.43  -2.34  -2.29  -2.24  -2.15   2180    1.0\n",
    "lp__         -176.8    0.03   1.08 -179.7 -177.2 -176.5 -176.0 -175.8   1662    1.0\n",
    "\n",
    "big_expensive_norm\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             6.28     0.2   4.22   1.04   5.59   6.55   7.49  11.03    451   1.01\n",
    "sigma0          4.17    0.37   8.47   1.18    1.9   2.69   4.17  14.81    520   1.01\n",
    "mu[1]           6.73  2.8e-4   0.02   6.68   6.71   6.73   6.74   6.77   8144    1.0\n",
    "mu[2]           8.97  2.8e-4   0.03   8.92   8.95   8.97   8.99   9.02   7870    1.0\n",
    "mu[3]           6.07  3.0e-4   0.03   6.02   6.06   6.07   6.09   6.12   7328    1.0\n",
    "mu[4]           4.58  3.0e-4   0.03   4.53   4.56   4.58   4.59   4.63   7524    1.0\n",
    "sigma           0.52  9.9e-5 8.8e-3    0.5   0.51   0.52   0.53   0.54   7847    1.0\n",
    "ypred[1]        6.73  5.8e-3   0.52    5.7   6.38   6.73   7.07   7.77   8051    1.0\n",
    "ypred[2]        8.96  5.8e-3   0.52   7.95   8.62   8.96   9.31   9.98   7932    1.0\n",
    "ypred[3]        6.08  5.7e-3   0.52   5.08   5.74   6.08   6.43   7.08   8130    1.0\n",
    "ypred[4]        4.57  5.9e-3   0.52   3.56   4.22   4.57   4.93   5.58   7881    1.0\n",
    "log_lik[1]     -1.06  6.7e-4   0.06  -1.18   -1.1  -1.05  -1.02  -0.94   8167    1.0\n",
    "log_lik[2]     -0.92  6.2e-4   0.06  -1.03  -0.95  -0.91  -0.88  -0.81   7886    1.0\n",
    "log_lik[3]     -0.51  4.1e-4   0.04  -0.59  -0.54  -0.51  -0.49  -0.45   7310    1.0\n",
    "...\n",
    "log_lik[1698]  -0.95  6.4e-4   0.06  -1.07  -0.99  -0.95  -0.91  -0.85   7888    1.0\n",
    "log_lik[1699]  -3.21  1.7e-3   0.14   -3.5   -3.3  -3.21  -3.11  -2.93   7429    1.0\n",
    "log_lik[1700]  -2.22  1.2e-3   0.11  -2.44  -2.29  -2.22  -2.14  -2.01   7619    1.0\n",
    "lp__          254.22    0.06   2.22 248.95 253.06 254.64 255.81 257.27   1373   1.01\n",
    "\n",
    "big_expensive_laplace\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             6.48    0.05   2.49   1.45   5.61   6.55   7.46  11.11   2323    1.0\n",
    "sigma0          3.93     0.1   4.59   1.19   1.92    2.7   4.21  14.02   2161    1.0\n",
    "mu[1]            6.7  4.1e-4   0.03   6.64   6.67    6.7   6.72   6.76   6267    1.0\n",
    "mu[2]           8.89  2.7e-4   0.02   8.85   8.88   8.89   8.91   8.93   6163    1.0\n",
    "mu[3]           6.12  2.8e-4   0.02   6.08   6.11   6.12   6.14   6.16   6355    1.0\n",
    "mu[4]           4.47  4.4e-4   0.03   4.42   4.45   4.46   4.49   4.54   5216    1.0\n",
    "sigma           0.42  1.2e-4   0.01    0.4   0.41   0.42   0.43   0.44   6763    1.0\n",
    "ypred[1]         6.7  6.6e-3    0.6   5.42   6.41    6.7   6.99   7.99   8159    1.0\n",
    "ypred[2]         8.9  6.9e-3   0.61   7.65   8.61   8.89   9.19  10.22   7739    1.0\n",
    "ypred[3]        6.13  6.6e-3   0.58   4.88   5.84   6.12   6.42   7.38   7774    1.0\n",
    "ypred[4]        4.47  6.6e-3   0.59   3.21   4.18   4.46   4.76   5.74   7911    1.0\n",
    "log_lik[1]     -1.31  9.8e-4   0.08  -1.47  -1.37  -1.31  -1.26  -1.17   6243    1.0\n",
    "log_lik[2]     -1.06  6.6e-4   0.05  -1.15  -1.09  -1.06  -1.02  -0.96   6056    1.0\n",
    "log_lik[3]     -0.81  6.6e-4   0.05   -0.9  -0.85  -0.81  -0.77   -0.7   6387    1.0\n",
    "...\n",
    "log_lik[1698]   -1.1  6.6e-4   0.05  -1.19  -1.13   -1.1  -1.06   -1.0   6040    1.0\n",
    "log_lik[1699]  -2.94  8.9e-4   0.07  -3.08  -2.99  -2.94  -2.89   -2.8   6707    1.0\n",
    "log_lik[1700]  -2.01  1.1e-3   0.08  -2.19  -2.06  -2.01  -1.96  -1.88   5186    1.0\n",
    "lp__          -235.0    0.04   2.18 -240.1 -236.1 -234.6 -233.3 -231.9   2511    1.0\n",
    "\n",
    "big_expensive_logistic\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0              6.5    0.05   2.44   1.78   5.62   6.57   7.49  11.09   2415    1.0\n",
    "sigma0          3.81    0.09   3.78   1.16   1.91    2.7   4.22   13.4   1779    1.0\n",
    "mu[1]           6.72  3.0e-4   0.03   6.67    6.7   6.72   6.74   6.77   8376    1.0\n",
    "mu[2]           8.95  2.8e-4   0.02   8.91   8.94   8.95   8.97    9.0   6907    1.0\n",
    "mu[3]           6.08  2.9e-4   0.03   6.03   6.06   6.08    6.1   6.13   8292    1.0\n",
    "mu[4]           4.55  3.0e-4   0.03    4.5   4.53   4.55   4.57    4.6   7972    1.0\n",
    "sigma            0.3  6.6e-5 5.9e-3   0.29    0.3    0.3   0.31   0.31   8042    1.0\n",
    "ypred[1]        6.71  6.0e-3   0.55   5.62   6.38   6.71   7.03   7.83   8239    1.0\n",
    "ypred[2]        8.97  6.2e-3   0.55   7.85   8.63   8.96   9.31   10.1   8021    1.0\n",
    "ypred[3]        6.07  6.3e-3   0.55   4.96   5.74   6.07    6.4   7.17   7573    1.0\n",
    "ypred[4]        4.54  6.5e-3   0.55   3.44   4.21   4.55   4.88   5.65   7263    1.0\n",
    "log_lik[1]     -1.17  8.1e-4   0.07  -1.32  -1.22  -1.17  -1.12  -1.03   8302    1.0\n",
    "log_lik[2]     -0.99  6.7e-4   0.06  -1.11  -1.03  -0.99  -0.95  -0.89   7235    1.0\n",
    "log_lik[3]     -0.55  5.3e-4   0.05  -0.64  -0.58  -0.55  -0.51  -0.45   8340    1.0\n",
    "...\n",
    "log_lik[1699]  -3.04  1.2e-3    0.1  -3.24  -3.11  -3.04  -2.97  -2.83   8145    1.0\n",
    "log_lik[1700]  -2.18  1.0e-3   0.09  -2.36  -2.24  -2.19  -2.12  -2.01   8146    1.0\n",
    "lp__           -1339    0.04   2.11  -1344  -1340  -1339  -1337  -1336   2495    1.0\n",
    "\n",
    "big_expensive_cauchy\n",
    "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "mu0             6.86    0.21   4.35   2.23   5.67   6.56   7.49  12.66    431   1.01\n",
    "sigma0          4.11    0.25   6.09   1.17   1.92   2.73   4.25  15.38    570    1.0\n",
    "mu[1]            6.7  3.7e-4   0.03   6.63   6.67    6.7   6.72   6.77   8484    1.0\n",
    "mu[2]           8.91  1.9e-4   0.02   8.87    8.9   8.91   8.92   8.94   8082    1.0\n",
    "mu[3]           6.11  3.1e-4   0.03   6.06   6.09   6.11   6.13   6.17   8720    1.0\n",
    "mu[4]            4.4  4.2e-4   0.04   4.33   4.38    4.4   4.43   4.48   7751    1.0\n",
    "sigma           0.32  1.1e-4   0.01    0.3   0.32   0.32   0.33   0.34   8073    1.0\n",
    "ypred[1]        6.58    0.12  10.59   2.41   6.37   6.69   7.02  10.62   8158    1.0\n",
    "ypred[2]        9.91    0.69  61.02   4.97   8.58   8.91   9.22  13.04   7907    1.0\n",
    "ypred[3]        5.15     0.6  54.07   2.36   5.78   6.11   6.43  10.22   8008    1.0\n",
    "ypred[4]        3.82    0.51  45.71  -0.06   4.07   4.41   4.73   8.55   7999    1.0\n",
    "log_lik[1]     -1.57  9.6e-4   0.09  -1.75  -1.63  -1.58  -1.51   -1.4   8343    1.0\n",
    "log_lik[2]     -1.33  5.2e-4   0.05  -1.42  -1.36  -1.33  -1.29  -1.23   8481    1.0\n",
    "log_lik[3]     -0.96  9.4e-4   0.09  -1.12  -1.01  -0.96   -0.9  -0.78   8710    1.0\n",
    "...\n",
    "log_lik[1698]  -1.37  5.1e-4   0.05  -1.46   -1.4  -1.37  -1.34  -1.28   8504    1.0\n",
    "log_lik[1699]  -2.86  5.7e-4   0.05  -2.96   -2.9  -2.87  -2.83  -2.76   8086    1.0\n",
    "log_lik[1700]   -2.1  8.3e-4   0.08  -2.25  -2.15   -2.1  -2.05  -1.95   8388    1.0\n",
    "lp__          294.32    0.06   2.22 288.92 293.14 294.73 295.95 297.34   1474    1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap norm\n",
    "psis-loo: -583.3168238995098\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 425 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "\n",
    " p_eff:510.8884098080273\n",
    "\n",
    "cheap laplace\n",
    "psis-loo: -604.7444389641925\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 425 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "\n",
    " p_eff:523.9722384139752\n",
    "\n",
    "cheap logistic\n",
    "psis-loo: -591.403197682519\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 425 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    " \n",
    " p_eff:514.5332321355345\n",
    "\n",
    "cheap cauchy\n",
    "psis-loo: -663.9309474288935\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 425 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "\n",
    " p_eff:577.2725209288639\n",
    "\n",
    "expensive norm\n",
    "psis-loo: -1304.9356792232736\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1700 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "\n",
    " p_eff:1276.5130961401203\n",
    "\n",
    "expensive laplace\n",
    "psis-loo: -1411.449696021804\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1700 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "\n",
    " p_eff:1377.5703130535733\n",
    "\n",
    "expensive logistic\n",
    "psis-loo: -1336.11417418032\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1700 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "\n",
    " p_eff:1305.5517347317807\n",
    "\n",
    "expensive cauchy\n",
    "psis-loo: -1650.8058242360069\n",
    "K-VALUES:\n",
    "\n",
    " (-inf;0.5] & 1700 & 100.0\n",
    " (0.5;0.7] & 0 & 0.0\n",
    " (0.7;1.0] & 0 & 0.0\n",
    " (1.0;inf) & 0 & 0.0\n",
    "\n",
    " p_eff:1611.4775267600676\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2. Stan codes for price variation (unbounded continuous):\n",
    "\n",
    "Data and parameters block is same for all four distributions. Normal can be seen fro A.1. The rest are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data {\n",
    "    int<lower=0> N; // number of data points\n",
    "    int<lower=0> K; // number of groups\n",
    "    int<lower=1,upper=K> x[N]; // group indicator\n",
    "    vector[N] y; //\n",
    "    real low;\n",
    "}\n",
    "parameters {\n",
    "    real mu0;             // prior mean\n",
    "    real<lower=low> sigma0; // prior std\n",
    "    vector[K] mu;         // group means\n",
    "    real<lower=low> sigma;  // common std\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Cauchy\n",
    "model {\n",
    "  mu ~ normal(mu0, sigma0);\n",
    "  y ~ cauchy(mu[x], sigma);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[K] ypred;\n",
    "  vector[N] log_lik;\n",
    "  // Posterior\n",
    "  for (i in 1:K)\n",
    "    ypred[i] = cauchy_rng(mu[i], sigma);\n",
    "  // Log_likelihood for psis_loo values\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = cauchy_lpdf(y[i] | mu[x[i]], sigma);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Laplace\n",
    "model {\n",
    "  mu ~ normal(mu0, sigma0);\n",
    "  y ~ double_exponential(mu[x], sigma);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[K] ypred;\n",
    "  vector[N] log_lik;\n",
    "  // Posterior\n",
    "  for (i in 1:K)\n",
    "    ypred[i] = double_exponential_rng(mu[i], sigma);\n",
    "  // Log_likelihood for psis_loo values\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = double_exponential_lpdf(y[i] | mu[x[i]], sigma);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Logistic\n",
    "model {\n",
    "  mu ~ normal(mu0, sigma0);\n",
    "  y ~ logistic(mu[x], sigma);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[K] ypred;\n",
    "  vector[N] log_lik;\n",
    "  // Posterior\n",
    "  for (i in 1:K)\n",
    "    ypred[i] = logistic_rng(mu[i], sigma);\n",
    "  // Log_likelihood for psis_loo values\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = logistic_lpdf(y[i] | mu[x[i]], sigma);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PYTHON CODE Final version for Price Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import glob\n",
    "from psis import psisloo\n",
    "import winsound\n",
    "\n",
    "# Sound for code finishing\n",
    "duration = 2000  # millisecond\n",
    "freq = 440  # Hz\n",
    "\n",
    "small_data_path = \"../data/small/\"\n",
    "smallFiles = glob.glob(small_data_path + \"*.csv\")\n",
    "big_data_path = \"../data/big/\"\n",
    "bigFiles = glob.glob(big_data_path + \"*.csv\")\n",
    "# Features:\n",
    "# \"date\",\n",
    "# \"marketcap\",\n",
    "# \"price\",\n",
    "# \"txVol\",\n",
    "# \"fees\"\n",
    "PSIS_COMPARISONS = {}\n",
    "\n",
    "\n",
    "def psispeffk(log_lik, name):\n",
    "    loo, loos, kw = psisloo(log_lik)\n",
    "    print(\"\\n\")\n",
    "    print(\"psis-loo:\", loo)\n",
    "    err_05 = 0\n",
    "    err_07 = 0\n",
    "    err_1 = 0\n",
    "    err_inf = 0\n",
    "    for i in range(0, len(kw)):\n",
    "        if kw[i] <= 0.5:\n",
    "            err_05 += 1\n",
    "        elif kw[i] <= 0.7:\n",
    "            err_07 += 1\n",
    "        elif kw[i] <= 1.0:\n",
    "            err_1 += 1\n",
    "        else:\n",
    "            err_inf += 1\n",
    "    _sum = 0\n",
    "    for i in range(0, 30):\n",
    "        _sum += np.log(np.mean(np.exp(log_lik[:, i])))\n",
    "\n",
    "    PSIS_COMPARISONS[name] = \"psis-loo: \" + str(\n",
    "        loo) + \"\\nK-VALUES:\\n\" + \"\\n\" + \" \" + \"(-inf;0.5] &\" + \" \" + str(\n",
    "        err_05) + \" \" + \"&\" + \" \" + str(\n",
    "        100 * err_05 / len(kw)) + \"\\n\" + \" \" + \"(0.5;0.7] &\" + \" \" + str(\n",
    "        err_07) + \" \" + \"&\" + \" \" + str(\n",
    "        100 * err_07 / len(kw)) + \"\\n\" + \" \" + \"(0.7;1.0] &\" + \" \" + str(\n",
    "        err_1) + \" \" + \"&\" + \" \" + str(\n",
    "        100 * err_1 / len(kw)) + \"\\n\" + \" \" + \"(1.0;inf) &\" + \" \" + str(\n",
    "        err_inf) + \" \" + \"&\" + \" \" + str(100 * err_inf / len(\n",
    "        kw)) + \"\\n\" + \" \" + \"\\n\" + \"\\n\" + \" \" + \"p_eff:\" + str(_sum - loo)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def Bayesian_Procedure_hier(hier_data, id_name, _cheap_coins):\n",
    "    # Distributions\n",
    "    stan_names = [\n",
    "        # \"norm_mix.stan\"\n",
    "        \"norm.stan\",\n",
    "        # Positive\n",
    "        # \"lognormal.stan\"\n",
    "        # \"chi.stan\",\n",
    "        # \"inv_chi.stan\",\n",
    "        # \"weibull.stan\"\n",
    "        # Continuous\n",
    "        \"laplace.stan\",\n",
    "        \"logistic.stan\",\n",
    "        \"cauchy.stan\"\n",
    "    ]\n",
    "    # g for graphs, k groups for bayes\n",
    "    k_cheap = []\n",
    "    g_cheap = {}\n",
    "    k_exp = []\n",
    "    g_exp = {}\n",
    "    for coin in hier_data:\n",
    "        # xrp is bugged\n",
    "        if coin != \"xrp\":\n",
    "            mc = hier_data[coin][\"marketcap\"].tolist()[-1] // 1000000\n",
    "            data = hier_data[coin][\"price\"].tolist()\n",
    "            print(coin, len(data))\n",
    "            log_data = np.log(data)\n",
    "            if coin in _cheap_coins:\n",
    "                k_cheap.append(log_data)\n",
    "                g_cheap[coin] = (log_data, mc)\n",
    "            else:\n",
    "                k_exp.append(log_data)\n",
    "                g_exp[coin] = (log_data, mc)\n",
    "\n",
    "    g_set = {\n",
    "        \"cheap\": g_cheap,\n",
    "        \"expensive\": g_exp\n",
    "    }\n",
    "    for g_sub_name in g_set:\n",
    "        g = g_set[g_sub_name]\n",
    "        for coin in g:\n",
    "            # coin_tuple 0 - data, 1 - marketcap\n",
    "            c_t = g[coin]\n",
    "            plt.hist(c_t[0], bins=50,\n",
    "                     rwidth=1, alpha=0.7, label=coin + \" \" + str(c_t[1]))\n",
    "        plt.grid(False)\n",
    "        plt.title(id_name + \" \" + g_sub_name + \" coins\")\n",
    "        plt.xlabel(\"log price (USD)\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.legend()\n",
    "        plt.savefig(id_name + \"_\" + g_sub_name + \"_prices.png\")\n",
    "        plt.clf()\n",
    "    k_set = {\n",
    "        \"cheap\": k_cheap\n",
    "        \"expensive\": k_exp\n",
    "    }\n",
    "    for k_sub_name in k_set:\n",
    "        k_groups = k_set[k_sub_name]\n",
    "        N = len(k_groups[0])  # Observations\n",
    "        K = len(k_groups)  # Groups/coins\n",
    "        h_flat = np.transpose(k_groups).flatten()\n",
    "        h_x = np.tile(np.arange(1, K + 1), N)\n",
    "        for stan_name in stan_names:\n",
    "            print(stan_name)\n",
    "            with open(\"stan/cont/\" + stan_name, 'r') as stan_file:\n",
    "                stan_code = stan_file.read()\n",
    "            hier_model = pystan.StanModel(model_code=stan_code)\n",
    "            stan_data = dict(\n",
    "                N=len(h_flat),\n",
    "                K=K,\n",
    "                x=h_x,\n",
    "                y=h_flat,\n",
    "                low=np.nextafter(0, 1)\n",
    "            )\n",
    "            # Stan results\n",
    "            fit = hier_model.sampling(data=stan_data, iter=4000)\n",
    "            with open(\"Fits.txt\", \"a\") as text_file:\n",
    "                print(id_name + \"_\" + k_sub_name + \"_\" + stan_name + \"\\n\" +\n",
    "                      str(fit), file=text_file)\n",
    "            samples = fit.extract(permuted=True)\n",
    "            posterior_data = samples[\"ypred\"]\n",
    "            post_g_set = {}\n",
    "            i = 0\n",
    "            # Complex for loop for plotting the posterior. Don't bother to read.\n",
    "            # Need labels. Assuming they go in same order.\n",
    "            no_error = False\n",
    "            for g_sub_name in g_set:\n",
    "                # if cheap==cheap\n",
    "                if g_sub_name == k_sub_name:\n",
    "                    # Get dictionary of cheap or exp coins\n",
    "                    g = g_set[g_sub_name]\n",
    "                    # Get coin name to put posterior samples into dictionary\n",
    "                    for coin in g:\n",
    "                        # g tuple 0 - data, 1 - marketcap, coin - name\n",
    "                        if len(posterior_data.shape) == 1:\n",
    "                            post_g_set[coin] = posterior_data\n",
    "                        else:\n",
    "                            post_g_set[coin] = posterior_data[:, i]\n",
    "                        try:\n",
    "                            plt.hist(post_g_set[coin], bins=50,\n",
    "                                     rwidth=1, alpha=0.7,\n",
    "                                     label=coin)\n",
    "                            no_error = True\n",
    "                        except:\n",
    "                            print(\"NaN\")\n",
    "                        i += 1\n",
    "            if no_error:\n",
    "                plt.grid(False)\n",
    "                plt.title(\"posterior \" + id_name + \" \" + k_sub_name + \" \" +\n",
    "                          stan_name.split(\".\")[0])\n",
    "                plt.xlabel(\"log price (USD)\")\n",
    "                plt.ylabel(\"count\")\n",
    "                plt.legend()\n",
    "                plt.savefig(\n",
    "                    \"post_\" + id_name + \"_\" + k_sub_name + \"_\" +\n",
    "                    stan_name.split(\".\")[\n",
    "                        0] + \".png\")\n",
    "                plt.clf()\n",
    "            psispeffk(samples[\"log_lik\"], k_sub_name + stan_name)\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    coins = {}\n",
    "    for file in smallFiles:\n",
    "        name = file.split(\"\\\\\")[1].split(\".\")[0]\n",
    "        coins[name] = pd.read_csv(file, index_col=0)\n",
    "    cheap_coins = [\"dgb\", \"xvg\"]\n",
    "    Bayesian_Procedure_hier(coins, \"small\", cheap_coins)\n",
    "    for name in PSIS_COMPARISONS:\n",
    "        with open(\"psis_loo_vals.txt\", \"a\") as text_file:\n",
    "            print(\n",
    "                \"small\\n\" + name + \"\\n\" + PSIS_COMPARISONS[name],\n",
    "                file=text_file\n",
    "            )\n",
    "    PSIS_COMPARISONS={}\n",
    "    coins = {}\n",
    "    for file in bigFiles:\n",
    "        name = file.split(\"\\\\\")[1].split(\".\")[0]\n",
    "        coins[name] = pd.read_csv(file, index_col=0)\n",
    "    cheap_coins = [\"ada\"]\n",
    "    Bayesian_Procedure_hier(coins, \"big\", cheap_coins)\n",
    "    for name in PSIS_COMPARISONS:\n",
    "        with open(\"psis_loo_vals.txt\", \"a\") as text_file:\n",
    "            print(\n",
    "                \"big\\n\" + name + \"\\n\" + PSIS_COMPARISONS[name],\n",
    "                file=text_file\n",
    "            )\n",
    "    winsound.Beep(freq, duration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
